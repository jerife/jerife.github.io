<!DOCTYPE html>
<html lang="en">
<!-- Beautiful Jekyll 5.0.0 | Copyright Dean Attali 2020 -->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

  

  <title>Seq2Seq(Sequence to Sequence) 이해하기</title>

  
  <meta name="author" content="Jerife">
  

  <meta name="description" content="Seq2Seq의 Encoder / Decoder">

  

  

  <link rel="alternate" type="application/rss+xml" title="Jerife" href="http://localhost:4000/feed.xml">

  

  

  

  


  
    
      
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">


    
      
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">


    
  

  
    
      <link rel="stylesheet" href="/assets/css/bootstrap-social.css">
    
      <link rel="stylesheet" href="/assets/css/beautifuljekyll.css">
    
  

  

  
  
  

  

  
  <meta property="og:site_name" content="Jerife">
  <meta property="og:title" content="Seq2Seq(Sequence to Sequence) 이해하기">
  <meta property="og:description" content="Seq2Seq의 Encoder / Decoder">

  
  <meta property="og:image" content="http://localhost:4000/assets/img/avatar-icon.png">
  

  
  <meta property="og:type" content="article">
  <meta property="og:article:author" content="Jerife">
  <meta property="og:article:published_time" content="2021-06-07T00:00:00-04:00">
  <meta property="og:url" content="http://localhost:4000/2021-06-07-seq2seq/">
  <link rel="canonical" href="http://localhost:4000/2021-06-07-seq2seq/">
  

  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:site" content="@">
  <meta name="twitter:creator" content="@">

  <meta property="twitter:title" content="Seq2Seq(Sequence to Sequence) 이해하기">
  <meta property="twitter:description" content="Seq2Seq의 Encoder / Decoder">

  
  <meta name="twitter:image" content="http://localhost:4000/assets/img/avatar-icon.png">
  

  


  

  
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/log.ico/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/log.ico/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/log.ico/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/log.ico/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/log.ico/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/log.ico/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/log.ico/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/log.ico/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/log.ico/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/log.ico/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/log.ico/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/log.ico/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/log.ico/favicon-16x16.png">
  <link rel="manifest" href="/assets/log.ico/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/log.ico/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
</head>




<body>

  


  <nav class="navbar navbar-expand-xl navbar-light fixed-top navbar-custom top-nav-regular"><a class="navbar-brand" href="http://localhost:4000/">Jerife</a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="main-navbar">
    <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="/aboutme">About Me</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="https://jerife.github.io">Home</a>
          </li></ul>
  </div>

  

  
    <div class="avatar-container">
      <div class="avatar-img-border">
        <a href="http://localhost:4000/">
          <img alt="Navigation bar avatar" class="avatar-img" src="/assets/img/avatar-icon.png" />
        </a>
      </div>
    </div>
  

</nav>


  <!-- TODO this file has become a mess, refactor it -->







<header class="header-section ">

<div class="intro-header no-img">
  <div class="container-md">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
        <div class="post-heading">
          <h1>Seq2Seq(Sequence to Sequence) 이해하기</h1>
          
            
              <h2 class="post-subheading">Seq2Seq의 Encoder / Decoder</h2>
            
          

          
            <span class="post-meta">Posted on June 7, 2021</span>
            
            
          
        </div>
      </div>
    </div>
  </div>
</div>
</header>





<div class=" container-md ">
  <div class="row">
    <div class=" col-xl-8 offset-xl-2 col-lg-10 offset-lg-1 ">

      
        
        
        

        <div id="header-gh-btns">
          
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=jerife&repo=jerife.github.io&type=star&count=true" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=jerife&type=follow&count=true" frameborder="0" scrolling="0" width="220px" height="20px"></iframe>
              
            
          
        </div>
      

      

      <article role="main" class="blog-post">
        <h2 id="seq2seq이란">Seq2Seq이란?</h2>
<p>Seq2Seq는 Sequence to Sequence의 약자로써, 시퀀스 데이터(언어, 시계열 데이터 등)를 또 다른 시퀀스 데이터로 변환해주는 모델입니다. <br />
Seq2Seq 모델은 RNN모델(RNN, LSTM, GRU)등을 순환성을 기반으로 사용 되기에 [<a href="https://jerife.github.io/2021-06-05-rnn/">RNN(Recurrent Neural Network) 이해하기</a>] | [<a href="https://jerife.github.io/2021-06-06-lstm/">LSTM(Long Short-Term Memory) 이해하기</a>] 부분을 먼저 학습하셔야합니다. <br /></p>

<p><img src="https://user-images.githubusercontent.com/68190553/121118577-0ebd6280-c855-11eb-8717-5a1b232331ee.gif" alt="seq2seq_gif_1" class="mx-auto d-block" /> 
Seq2Seq 모델은 보이는 움짤과 같이 크게 <strong>인코더 (Encoder)</strong> 부분과 <strong>디코더 (Decoder)</strong> 부분으로 나눌 수 있습니다. <br />
간단하게 인코더는 문자를 데이터로 변환시키고, 디코더는 데이터를 문자로 변환시키는 역할을 합니다.</p>

<hr />
<h3 id="rnn-of-seq2seq">RNN of Seq2Seq</h3>
<p>여기 Seq2Seq의 Encoder와 Decoder에선 RNN 기반 모델들을 (RNN, LSTM, GRU) 사용합니다. 이번글에선 LSTM 모델이 사용된다 가정하겠습니다. <br />
<img src="https://user-images.githubusercontent.com/68190553/121049358-97ef7d80-c7f2-11eb-8cf4-83117dffe5ba.png" alt="lstm_img_4" class="mx-auto d-block" /> <br /></p>

<p>LSTM모델은 시간에 따른 데이터를 순환 시켜주는 “ht” 값과 / 중요한 데이터는 기억하고, 아닌 데이터는 잊는 기억셀 “Ct”가 있습니다. 이 두 값은 다음셀로 계속 사용전달 되어, 다음셀에 영향을 줍니다. <br />
이렇게 다음 층으로 계속 전달 되는 층을 <strong>HIdden state</strong> 라고도 부릅니다. <br /></p>

<h3 id="seq2seq-architecture">Seq2Seq Architecture</h3>
<p>Seq2Seq에서 사용 될 RNN모델을 정했기에 이제 Encoder / Decoder 와 이 둘을 이어주는 Context(문맥) 부분을 이해해보겠습니다. 
<img src="https://user-images.githubusercontent.com/68190553/121048577-e2bcc580-c7f1-11eb-9c39-2cb0f717ce2d.gif" alt="image" class="mx-auto d-block" /></p>
<h4 id="1-encoder">[1] Encoder</h4>
<p><img width="434" alt="seq2seq_img_2" src="https://user-images.githubusercontent.com/68190553/121124975-c0ae5c00-c860-11eb-9e27-ed281412fcf8.png" class="mx-auto d-block" /></p>

<p>Encoder부분을 보면 “je suis étudiant” 라는 문장이 Word level로(단어마다) RNN모델에 한개씩 들어가는 것을 알 수 있습니다. <br />
셀에 단어가 들어갈떄 마다 <strong>HIdden state</strong>(LSTM의 기억셀 Ct와, 결과값 ht) 값이 나와서 다음셀에 영향을 주는 것을 볼 수 있습니다. <br />
이 후 마지막 셀에 “étudiant” 단어가 들어가는 순간 <strong>HIdden state</strong>값이 나오고 그 값이 Decoder에 들어가는 것을 볼 수 있습니다. 우리는 Encoder부분의 마지막 셀에서 나오는 HIdden state를 <strong>Context Vector</strong>(문맥)이라고도 부릅니다.<br /></p>

<h4 id="2-context-vector">[2] Context Vector</h4>
<p><img width="27" alt="seq2seq_img_4" src="https://user-images.githubusercontent.com/68190553/121125066-e2a7de80-c860-11eb-8fd7-20e3e2ebefb5.png" class="mx-auto d-block" /></p>

<p><strong>Context Vector</strong>(문맥)으로 불리는 Encoder부분의 마지막 셀에서 나오는 HIdden state에 대해서 추가적인 설명을 하겠습니다. <br />
Context Vector는 입력값(“je suis étudiant”)의 모든 정보를 모아 놓은 동시에, <strong>고정된 크기의 벡터</strong>이기도 합니다. <br />
고정된 크기의 벡터는 많은양의 데이터도 꾹꾹 눌러서 압축시켜야하기 떄문에, 정보 손실률이 있다는 단점이 있지만, 차 후 <strong>Attention Mechanism</strong>을 통해 단점을 해결할 수 있게 됩니다. 이 글에선 Attention Mechanism에 대해선 다루지 않겠습니다.  <br /></p>

<h4 id="3-decoder">[3] Decoder</h4>
<p><img width="417" alt="seq2seq_img_3" src="https://user-images.githubusercontent.com/68190553/121125051-db80d080-c860-11eb-9b1c-038c2df283bc.png" class="mx-auto d-block" /></p>

<p>Decoder도 Encoder과 마찬가지로 정보를 받아, RNN을 통해 결과를 예측하는 것 까지는 같습니다.
Decoder는 유일한 정보인 Context Vector만을 정보로 받아 “i am a student”와 같은 결과를 출력합니다.</p>

<h3 id="seq2seq-개선">Seq2Seq 개선</h3>
<p>Seq2Seq 개선하는 방법 중 하나는 위에서 언급한 Attention Mechanism이 가장 인상 깊겠지만, 그전에 간단한 방법으로 개선하는 법을 언급하겠습니다. <br />
=&gt; 입력데이터의 순서를 뒤집는다. <br />
<strong>ex) “안녕 나는 딥러닝을 좋아하는 파이썬돌이야 .” =&gt; “. 파이썬돌이야 좋아하는 딥러닝을 나는 안녕”</strong> <br />
이렇게 언어 순서를 바꿔주는 것 만으로도 Context Vector에 다른 작용을해서 좋은 결과를 추출한다고 합니다.</p>
<h6 id="간단하게-원리를-위주로-알아봤으며-파이토치-코드를-바탕으로-pythonic하게-이해해보겠습니다-해당-코드는-나동빈님의-깃허브를-바탕으로-제작되었음에-출처를-남깁니다-">간단하게 원리를 위주로 알아봤으며, 파이토치 코드를 바탕으로 Pythonic하게 이해해보겠습니다. 해당 코드는 나동빈님의 깃허브를 바탕으로 제작되었음에 출처를 남깁니다. <br /></h6>

<h2 id="pytorch-code">Pytorch Code</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pytorch</span>
<span class="kn">import</span> <span class="nn">pytorch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout_ratio</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="c1"># 임베딩(embedding)은 원-핫 인코딩(one-hot encoding)을 특정 차원의 임베딩으로 매핑하는 레이어
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>

        <span class="c1"># LSTM 레이어
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout_ratio</span><span class="p">)</span>
        
        <span class="c1"># 드롭아웃(dropout)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_ratio</span><span class="p">)</span>

    <span class="c1"># 인코더는 소스 문장을 입력으로 받아 문맥 벡터(context vector)를 반환        
</span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>

        <span class="n">outputs</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
      
        <span class="c1"># 문맥 벡터(context vector) 반환
</span>        <span class="k">return</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout_ratio</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="c1"># 임베딩(embedding)은 원-핫 인코딩(one-hot encoding) 말고 특정 차원의 임베딩으로 매핑하는 레이어
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>

        <span class="c1"># LSTM 레이어
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout_ratio</span><span class="p">)</span>
        
        <span class="c1"># FC 레이어 (인코더와 구조적으로 다른 부분)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fc_out</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
        
        <span class="c1"># 드롭아웃(dropout)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_ratio</span><span class="p">)</span>

    <span class="c1"># 디코더는 현재까지 출력된 문장에 대한 정보를 입력으로 받아 타겟 문장을 반환     
</span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">):</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="nb">input</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
        <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">))</span>

        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc_out</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Seq2Seq</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

    <span class="c1"># 학습할 때는 완전한 형태의 소스 문장, 타겟 문장, teacher_forcing_ratio를 넣기
</span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">teacher_forcing_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="c1"># 먼저 인코더를 거쳐 문맥 벡터(context vector)를 추출
</span>        <span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>

        <span class="c1"># 디코더(decoder)의 최종 결과를 담을 텐서 객체 만들기
</span>        <span class="n">trg_len</span> <span class="o">=</span> <span class="n">trg</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 단어 개수
</span>        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">trg</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 배치 크기
</span>        <span class="n">trg_vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">.</span><span class="n">output_dim</span> <span class="c1"># 출력 차원
</span>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">trg_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">trg_vocab_size</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># 첫 번째 입력은 항상 &lt;sos&gt; 토큰
</span>        <span class="nb">input</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># 타겟 단어의 개수만큼 반복하여 디코더에 포워딩(forwarding)
</span>        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">trg_len</span><span class="p">):</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span>

            <span class="n">outputs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span> <span class="c1"># FC를 거쳐서 나온 현재의 출력 단어 정보
</span>            <span class="n">top1</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 가장 확률이 높은 단어의 인덱스 추출
</span>
            <span class="c1"># teacher_forcing_ratio: 학습할 때 실제 목표 출력(ground-truth)을 사용하는 비율
</span>            <span class="n">teacher_force</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">teacher_forcing_ratio</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">if</span> <span class="n">teacher_force</span> <span class="k">else</span> <span class="n">top1</span> <span class="c1"># 현재의 출력 결과를 다음 입력에서 넣기
</span>        
        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></div>
<p><br /></p>

<blockquote>
  <p>이미지/ 코드 출처</p>
  <ul>
    <li>https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice ( 코드 )</li>
    <li>http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/ (이미지)</li>
    <li>밑바닥부터 시작하는 딥러닝 2 / 사이토 고키 / 한빛 미디어</li>
  </ul>
</blockquote>

      </article>

      
        <div class="blog-tags">
          <span>Tags:</span>
          
            <a href="/tags#NLP">NLP</a>
          
            <a href="/tags#Seq2Seq">Seq2Seq</a>
          
        </div>
      

      

      
        <!-- Check if any share-links are active -->




<section id = "social-share-section">
  <span class="sr-only">Share: </span>

  
    <a href="https://twitter.com/intent/tweet?text=Seq2Seq%28Sequence+to+Sequence%29+%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0&url=http%3A%2F%2Flocalhost%3A4000%2F2021-06-07-seq2seq%2F"
      class="btn btn-social-icon btn-twitter" title="Share on Twitter">
      <span class="fab fa-fw fa-twitter" aria-hidden="true"></span>
      <span class="sr-only">Twitter</span>
    </a>
  

  
    <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2F2021-06-07-seq2seq%2F"
      class="btn btn-social-icon btn-facebook" title="Share on Facebook">
      <span class="fab fa-fw fa-facebook" aria-hidden="true"></span>
      <span class="sr-only">Facebook</span>
    </a>
  

  
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2F2021-06-07-seq2seq%2F"
      class="btn btn-social-icon btn-linkedin" title="Share on LinkedIn">
      <span class="fab fa-fw fa-linkedin" aria-hidden="true"></span>
      <span class="sr-only">LinkedIn</span>
    </a>
  

  

</section>



      

      <ul class="pagination blog-pager">
        
        <li class="page-item previous">
          <a class="page-link" href="/2021-06-06-lstm/" data-toggle="tooltip" data-placement="top" title="LSTM(Long Short-Term Memory) 이해하기">&larr; Previous Post</a>
        </li>
        
        
      </ul>
      
  <div class="disqus-comments">
  <div class="comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
	  var disqus_shortname = 'beautiful-jekyll';
	  /* ensure that pages with query string get the same discussion */
	  var url_parts = window.location.href.split("?");
	  var disqus_url = url_parts[0];
	  (function() {
		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	  })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</div>
  
  

  




    </div>
  </div>
</div>


  <footer>
  <div class="container-md beautiful-jekyll-footer">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
      <ul class="list-inline text-center footer-links"><li class="list-inline-item">
    <a href="/feed.xml" title="RSS">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">RSS</span>
    </a>
  </li><li class="list-inline-item">
    <a href="mailto:jerife@naver.com" title="Email me">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">Email me</span>
   </a>
  </li><li class="list-inline-item">
    <a href="https://github.com/jerife" title="GitHub">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">GitHub</span>
   </a>
  </li></ul>

      
      <p class="copyright text-muted">
      
        Jerife
        &nbsp;&bull;&nbsp;
      
      2021

      
        &nbsp;&bull;&nbsp;
        <span class="author-site">
          <a href="http://localhost:4000/">Jerife.github.io</a>
        </span>
      

      
      </p>
      <p class="theme-by text-muted">
        Powered by
        <a href="https://beautifuljekyll.com">Beautiful Jekyll</a>
      </p>
      </div>
    </div>
  </div>
</footer>


  
  
    
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin="anonymous"></script>


  
    
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


  
    
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


  



  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
      <script src="/assets/js/beautifuljekyll.js"></script>
    
  









</body>
</html>
