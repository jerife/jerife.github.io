---
layout: post  (You Only Look Once) v3 이해하기
subtitle: 1-Stage Detection Model
gh-repo: jerife/jerife.github.io
gh-badge: [star, follow]
tags: [Computer Vision, Object Detection]
comments: true
---

<br/>
![yolo_img_1](https://user-images.githubusercontent.com/68190553/136654564-a8955779-5be8-4dd2-997d-a25a32d3160c.png){: .mx-auto.d-block :} <br/>

## YOLO란?
YOLO는 이전 포스팅인 2-stage 모델인 Faster RCNN과 다르게 대표적인 1-stage Object detection 모델입니다. <br/>
1-stage와 2-stage의 차이를 알기위해 구조를 먼저 언급하겠습니다. <br/>
> 1 stage: 이미지를 입력받아 한 모델에 한번에 Classification과 BoundingBox를 출력합니다.
> 2 stage: 이미지를 입력받고 Feature map을 하여, RPN에서 Region Proposal을 받아 Feature map에 대입해 학습합니다.

![yolo_img_2](https://user-images.githubusercontent.com/68190553/136654678-fa54308a-3ff4-489c-8cee-ef4bd3fc2f30.png){: .mx-auto.d-block :} <br/>
이는 Yolo v1의 구조입니다. Faster RCNN과 다르게 RPN부분이 따로 없는 것을 알 수 있습니다. <br/>
이 포스팅에선 Yolo에 혁명을 준, 3번쨰 버전인 v3에 대해 다뤄보겠습니다.  <br/><br/>
Yolo v3의 구조는 크게 "Backbone", "Neck", "Head" 3가지로 나눌 수 있습니다. 순서대로 설명해보겠습니다.

### [1] Backbone
Backbone은 "Feature Extractor"라고도 불립니다. 이미지를 모델에 input으로 사용해, 이미지의 특징(feature map)을 ouptput으로 내보내는 모델입니다. <br/>
대표적으론 CNN계열 모델들인 "ResNet", "DenseNet"등 Feature map을 output하는 어떠한 모델들도 Backbone으로 사용될 수 있습니다. <br/><br/>
하지만 Yolo v3에선 **DarkNet 53**이라는 모델을 사용했습니다. <br/>
![yolo_img_4](https://user-images.githubusercontent.com/68190553/136654864-4e9412ca-7cb6-447d-84e2-eb5ccf976036.png){: .mx-auto.d-block :} <br/>
> DarkNet 53의 Architecture





 
