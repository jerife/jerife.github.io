<!DOCTYPE html>
<html lang="en">
<!-- Beautiful Jekyll 5.0.0 | Copyright Dean Attali 2020 -->
<head></head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
  }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!--$f(x) = x^2$->
  

  

  

  <title>Review - A deep learning method for single-trial EEG classification in RSVP task based on spatiotemporal features of ERPs</title>

  
  <meta name="author" content="Jerife">
  

  <meta name="description" content="RSVP task based on spatiotemporal features of ERPs">

  

  

  
  <link rel="alternate" type="application/rss+xml" title="Jerife" href="http://localhost:4000/feed.xml">
  

  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-H3TE8W3M78"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-H3TE8W3M78');
</script>

  

  

  


  
    
      
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">


    
      
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">


    
  

  
    
      <link rel="stylesheet" href="/assets/css/bootstrap-social.css">
    
      <link rel="stylesheet" href="/assets/css/beautifuljekyll.css">
    
  

  

  
  
  

  

  
  <meta property="og:site_name" content="Jerife">
  <meta property="og:title" content="Review - A deep learning method for single-trial EEG classification in RSVP task based on spatiotemporal features of ERPs">
  <meta property="og:description" content="RSVP task based on spatiotemporal features of ERPs">

  
  <meta property="og:image" content="http://localhost:4000/assets/img/avatar-icon.png">
  

  
  <meta property="og:type" content="article">
  <meta property="og:article:author" content="Jerife">
  <meta property="og:article:published_time" content="2022-06-02T00:00:00+09:00">
  <meta property="og:url" content="http://localhost:4000/2022-06-02-A-deep-learning-method-for-single-trial-EEG-classification-in-RSVP-task-based-on-spatiotemporal-features-of-ERPs/">
  <link rel="canonical" href="http://localhost:4000/2022-06-02-A-deep-learning-method-for-single-trial-EEG-classification-in-RSVP-task-based-on-spatiotemporal-features-of-ERPs/">
  

  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:site" content="@">
  <meta name="twitter:creator" content="@">

  <meta property="twitter:title" content="Review - A deep learning method for single-trial EEG classification in RSVP task based on spatiotemporal features of ERPs">
  <meta property="twitter:description" content="RSVP task based on spatiotemporal features of ERPs">

  
  <meta name="twitter:image" content="http://localhost:4000/assets/img/avatar-icon.png">
  

  


  

  
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/log.ico/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/log.ico/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/log.ico/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/log.ico/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/log.ico/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/log.ico/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/log.ico/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/log.ico/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/log.ico/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/log.ico/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/log.ico/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/log.ico/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/log.ico/favicon-16x16.png">
  <link rel="manifest" href="/assets/log.ico/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/log.ico/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
</head>

<body>

  


  <nav class="navbar navbar-expand-xl navbar-light fixed-top navbar-custom top-nav-regular"><a class="navbar-brand" href="http://localhost:4000/">Jerife</a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="main-navbar">
    <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="/tags">Records</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="/aboutme">About Me</a>
          </li>
        <li class="nav-item">
          <a class="nav-link" id="nav-search-link" href="#" title="Search">
            <span id="nav-search-icon" class="fa fa-search"></span>
            <span id="nav-search-text">Search</span>
          </a>
        </li></ul>
  </div>

  

  
    <div class="avatar-container">
      <div class="avatar-img-border">
        <a href="http://localhost:4000/">
          <img alt="Navigation bar avatar" class="avatar-img" src="/assets/img/avatar-icon.png" />
        </a>
      </div>
    </div>
  

</nav>



<div id="beautifuljekyll-search-overlay">

  <div id="nav-search-exit" title="Exit search">✕</div>
  <input type="text" id="nav-search-input" placeholder="Search">
  <ul id="search-results-container"></ul>
  
  <script src="https://unpkg.com/simple-jekyll-search@latest/dest/simple-jekyll-search.min.js"></script>
  <script>
    var searchjson = '[ \
       \
        { \
          "title"    : "Review - Motion Imagery-BCI Based on EEG and Eye Movement Data Fusion", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-07-03-Motion-Imagery-BCI-Based-on-EEG-and-Eye-Movement-Data-Fusion/", \
          "date"     : "July  3, 2022" \
        }, \
       \
        { \
          "title"    : "Review - Hybrid EEG-EOG-based BCI system for Vehicle Control", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-06-20-Hybrid-EEG-EOG-based-BCI-system-for-Vehicle-Control/", \
          "date"     : "June 20, 2022" \
        }, \
       \
        { \
          "title"    : "Review - An autonomous hybrid brain-computer interface system combined with eye-tracking in virtual environment", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-06-19-An-autonomous-hybrid-brain-computer-interface-system-combined-with-eye-tracking-in-virtual-environment/", \
          "date"     : "June 19, 2022" \
        }, \
       \
        { \
          "title"    : "Review - User-defined walking-in-place gestures for VR locomotion", \
          "category" : "Virtual Reality", \
          "url"      : "/2022-06-13-User-defined-walking-in-place-gestures-for-VR-locomotion/", \
          "date"     : "June 13, 2022" \
        }, \
       \
        { \
          "title"    : "Review - A Sliding Window Common Spatial Pattern for Enhancing Motor Imagery Classification in EEG-BCI", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-06-08-A-Sliding-Window-Common-Spatial-Pattern-for-Enhancing-Motor-Imagery-Classification-in-EEG-BCI/", \
          "date"     : "June  8, 2022" \
        }, \
       \
        { \
          "title"    : "Review - The Effect of Multisensory Pseudo-Haptic Feedback on Perception of Virtual Weight", \
          "category" : "Virtual Reality", \
          "url"      : "/2022-06-07-The-Effect-of-Multisensory-Pseudo-Haptic-Feedback-on-Perception-of-Virtual-Weight/", \
          "date"     : "June  7, 2022" \
        }, \
       \
        { \
          "title"    : "Review - A deep learning method for single-trial EEG classification in RSVP task based on spatiotemporal features of ERPs", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-06-02-A-deep-learning-method-for-single-trial-EEG-classification-in-RSVP-task-based-on-spatiotemporal-features-of-ERPs/", \
          "date"     : "June  2, 2022" \
        }, \
       \
        { \
          "title"    : "Review - Artificial Intelligence for the Metaverse - A Survey", \
          "category" : "Virtual Reality", \
          "url"      : "/2022-05-30-Artificial-Intelligence-for-the-Metaverse-A-Survey/", \
          "date"     : "May 30, 2022" \
        }, \
       \
        { \
          "title"    : "Review - A hybrid BCI-controlled smart home system combining SSVEP and EMG for individuals with paralysis", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-05-25-A-hybrid-BCI-controlled-smart-home-system-combining-SSVEP-and-EMG-for-individuals-with-paralysis/", \
          "date"     : "May 25, 2022" \
        }, \
       \
        { \
          "title"    : "Review - An integrated deep learning model for motor intention recognition of multi-class EEG Signals in upper limb amputees", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-05-24-An-integrated-deep-learning-model-for-motor-intention-recognition-of-multi-class-EEG-Signals-in-upper-limb-amputees/", \
          "date"     : "May 24, 2022" \
        }, \
       \
        { \
          "title"    : "Review - VR Locomotion in the New Era of Virtual Reality An Empirical Comparison of Prevalent Techniques", \
          "category" : "Virtual Reality", \
          "url"      : "/2022-05-23-VR-Locomotion-in-the-New-Era-of-Virtual-Reality-An-Empirical-Comparison-of-Prevalent-Techniques/", \
          "date"     : "May 23, 2022" \
        }, \
       \
        { \
          "title"    : "Review - Brain Controlled Wheelchairs A Robotic Architecture", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-05-18-Brain-Controlled-Wheelchairs-A-Robotic-Architecture/", \
          "date"     : "May 18, 2022" \
        }, \
       \
        { \
          "title"    : "Review - Robust Classification of EEG Signal for Brain Computer Interface", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-05-17-Robust-classification-of-EEG-signal-for-brain-computer-interface/", \
          "date"     : "May 17, 2022" \
        }, \
       \
        { \
          "title"    : "Introduce to LUKE", \
          "category" : "Natural Language Processing", \
          "url"      : "/2022-01-03-luke/", \
          "date"     : "January  3, 2022" \
        }, \
       \
        { \
          "title"    : "2021년 한 해를 돌아보는 회고록", \
          "category" : "Diary", \
          "url"      : "/2021-12-31-2021end/", \
          "date"     : "December 31, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to ELECTRA", \
          "category" : "Natural Language Processing", \
          "url"      : "/2021-12-11-electra/", \
          "date"     : "December 11, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to RoBERTa", \
          "category" : "Natural Language Processing", \
          "url"      : "/2021-12-07-roberta/", \
          "date"     : "December  7, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to BERT", \
          "category" : "Natural Language Processing", \
          "url"      : "/2021-11-19-bert/", \
          "date"     : "November 19, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Transformer", \
          "category" : "Natural Language Processing", \
          "url"      : "/2021-11-17-transformer/", \
          "date"     : "November 17, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Attention Mechanism", \
          "category" : "Natural Language Processing", \
          "url"      : "/2021-11-16-attention/", \
          "date"     : "November 16, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to EfficientDet", \
          "category" : "Computer VisionObject Detection", \
          "url"      : "/2021-11-15-efficientdet/", \
          "date"     : "November 15, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to EfficientNet", \
          "category" : "Computer Vision", \
          "url"      : "/2021-10-28-efficientnet/", \
          "date"     : "October 28, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Yolo v3", \
          "category" : "Computer VisionObject Detection", \
          "url"      : "/2021-10-09-yolov3/", \
          "date"     : "October  9, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Faster R-CNN", \
          "category" : "Computer VisionObject Detection", \
          "url"      : "/2021-09-12-fasterrcnn/", \
          "date"     : "September 12, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Fast R-CNN", \
          "category" : "Computer VisionObject Detection", \
          "url"      : "/2021-09-10-fastrcnn/", \
          "date"     : "September 10, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to R-CNN", \
          "category" : "Computer VisionObject Detection", \
          "url"      : "/2021-07-25-rcnn/", \
          "date"     : "July 25, 2021" \
        }, \
       \
        { \
          "title"    : "Intriduce to ARIMA Model", \
          "category" : "Time Series", \
          "url"      : "/2021-06-26-arima/", \
          "date"     : "June 26, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Seq2Seq", \
          "category" : "Natural Language ProcessingTime Series", \
          "url"      : "/2021-06-08-seq2seq/", \
          "date"     : "June  8, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to LSTM", \
          "category" : "Natural Language ProcessingTime Series", \
          "url"      : "/2021-06-06-lstm/", \
          "date"     : "June  6, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to RNN", \
          "category" : "Natural Language ProcessingTime Series", \
          "url"      : "/2021-06-05-rnn/", \
          "date"     : "June  5, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to DenseNet", \
          "category" : "Computer Vision", \
          "url"      : "/2021-05-12-densenet/", \
          "date"     : "May 12, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to ResNet", \
          "category" : "Computer Vision", \
          "url"      : "/2021-05-11-resnet/", \
          "date"     : "May 11, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to CNN", \
          "category" : "Computer Vision", \
          "url"      : "/2021-05-10-cnn/", \
          "date"     : "May 10, 2021" \
        }, \
       \
        { \
          "title"    : "To start blog with Github", \
          "category" : "Diary", \
          "url"      : "/2021-04-27-first/", \
          "date"     : "April 27, 2021" \
        }, \
       \
       \
        { \
          "title"    : "About me", \
          "category" : "page", \
          "url"      : "/aboutme/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "All Records", \
          "category" : "page", \
          "url"      : "/tags/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page2/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page3/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page4/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page5/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page6/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page7/", \
          "date"     : "January 1, 1970" \
        } \
       \
    ]';
    searchjson = JSON.parse(searchjson);

    var sjs = SimpleJekyllSearch({
      searchInput: document.getElementById('nav-search-input'),
      resultsContainer: document.getElementById('search-results-container'),
      json: searchjson
    });
  </script>
</div>





  <!-- TODO this file has become a mess, refactor it -->







<header class="header-section ">

<div class="intro-header no-img">
  <div class="container-md">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
        <div class="post-heading">
          <h1>Review - A deep learning method for single-trial EEG classification in RSVP task based on spatiotemporal features of ERPs</h1>
          
            
              <h2 class="post-subheading">RSVP task based on spatiotemporal features of ERPs</h2>
            
          

          
            <span class="post-meta">Posted on June 2, 2022</span>
            
            
          
        </div>
      </div>
    </div>
  </div>
</div>
</header>





<div class=" container-md ">
  <div class="row">
    <div class=" col-xl-8 offset-xl-2 col-lg-10 offset-lg-1 ">

      
        
        
        

        <div id="header-gh-btns">
          
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=jerife&repo=jerife.github.io&type=star&count=true" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=jerife&type=follow&count=true" frameborder="0" scrolling="0" width="220px" height="20px"></iframe>
              
            
          
        </div>
      

      

      <article role="main" class="blog-post">
        <div align="center"><h2>A deep learning method for single-trial EEG classification in RSVP task based on spatiotemporal features of ERPs 논문 리뷰</h2></div>
<!--break-->

<hr />

<p><br /></p>

<h2 id="abstract">ABSTRACT</h2>

<p>대부분의 CNN 모델은 event-related potentials (ERP) 구성 요소의 phase-locked(위상 고정) 특성을 잘 고려하지 않습니다.</p>

<p>따라서 본 논문은 phase-locked(위상 고정) 특성을 이용해 ERP 구성 요소의 공간적인(spatial) 특징을 다른 주기마다 학습합니다.</p>

<h2 id="introduction">Introduction</h2>

<p>본 논문은 EEG classification 중 rapid serial visual presentation (RSVP) task를 다룹니다.</p>

<p>RSVP은 빠른 속도로 여러 이미지가 나타나며 User는 이미지를 보고 target과 non-target을 식별하는 task입니다.<br />
이때 event-related potentials (ERP)는 이미지 stumli에 의해 유발됩니다.</p>

<p class="box-warning">P300은 target 이미지에 의해 발생하지만 non-target 이미지에는 발생하지는 않습니다.</p>

<p>기존엔 아래와 같은 traditional machine learning로 task가 수행되었습니다.</p>
<ul>
  <li>linear discriminant analysis (LDA)</li>
  <li>Fisher linear discriminant (FLD)</li>
  <li>Hierarchical discriminant component analysis (HDCA)</li>
  <li>spatially weighted FLD (SWFP)</li>
  <li>principal components analysis (PCA)</li>
</ul>

<p>linear한 모델들은 faster하고 robust하지만 performance가 떨어진다는 단점이 있습니다.</p>

<p>반면 deep learning은 강력한 non linear하게 계산하며 다차원 데이터에서 계층적이고 본질적인 특징을 더 깊이 추출할 수 있습니다.</p>

<p>그중 CNN은 EEG 연구에서 중요한 시간적(temporal) 및 공간적(spatial) 특징을 추출하기 위해 별도로 컨볼루션을 작동하도록 구성할 수 있습니다.</p>

<p>CNN 기반 deep learning 모델중엔 EEG classification를 제안하는 모델들이 있습니다.</p>
<ul>
  <li><strong>[Shallow ConvNet / DeepConvNet]</strong> : EEG를 각각의 주파수 band에 temporal convolution를 이용해 분해한 후 spatial convolution를 합니다.</li>
  <li><strong>[EEGNet]</strong> : depthwise, separable convolution를 통해 temporal, spatial convolution을 강하게 매핑합니다.</li>
</ul>

<p>그러나 대부분의 CNN 모델은 event-related potentials (ERP) 구성 요소의 phase-locked(위상 고정) 특성을 잘 고려하지 않습니다.</p>

<p>기존 모델들은 가중치가 공유되는 convolution layer를 이용해 같은 spatial filter로 convolution되기에 다른 ERP 구성 요소들로부터 차별적인 정보를 얻을 수 없습니다.</p>

<h4 id="procedure">procedure</h4>
<p>따라서 본 논문은</p>
<ol>
  <li>convolution layer로 temporal정보를 추출하고 차원을 압축합니다.</li>
  <li>ERP 구성요소는 상대적으로 안정적인 지연 시간 및 파형과 같은 phase-locked(위상 고정) 특성을 가지므로, 다른 ERP의 위상을 학습하기 위해 개별 spatial filter로 데이터의 다른 주기를 학습힙니다.</li>
  <li>separable convolutional로 temporal feature을 추출한 뒤 FC layer와 softmax를 통해 classifer합니다.</li>
</ol>

<h2 id="material-and-methods">Material and methods</h2>
<h3 id="a-experiment-procedure">A. Experiment procedure</h3>
<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/171114941-cdeb591c-0dcd-4e31-bc89-5ff9b6e0e5d5.png" width="100%" />
</div>

<p>실험은 이미지 속에 보행자가 있는지 / 없는지 분류하는 task입니다.<br />
4 ssesion으로 구성되있으며, 각 ssesion은 50 block으로 구성됩니다. 그리고 각 block은 100개의 이미지를 10Hz마다 보여줍니다.</p>

<p>한 ssesion에 75개의 target 이미지가 랜덤하게 들어가며 P300 요소와 집중도가 떨어지지 않게하기 위해 각 block엔 1~2개의 target 이미지만 들어갑니다.</p>

<p>실험은 검은화면이 1초 유지되고 이후  0.2초깜박인 후에 위 내용의 task가 10초동안(100장의 이미지) 실행되고 5초간 휴식합니다.<br />
이 과정은 50(blocks) * 4(sessions) 진행됩니다.</p>

<h3 id="b-eeg-acquisition-and-preprocessing">B. EEG acquisition and preprocessing</h3>
<p>EEG는 60 Ag/AgCl electrodes에서 얻어졌으며 1000Hz로 샘플링 되었습니다.<br />
EEGLAB의 FIR filters로 0.3–28Hz BPF가 적용 되었습니다.
데이터는 1024개(대략 1.xx초)의 segment로 나눠졌습니다. 이 segment는 이미지 자극이 시작하기(onset) 0.2초 전에 진폭의 평균만큼 빼졌습니다.<br />
이후 1024개(대략 1.xx초)의 segment는 128 샘플로 downsample 되었습니다.(1개당 대략 0.008x초) 총 60개의 전극 x 128샘플의 shape를 갖습니다.</p>

<h3 id="c-neural-network-architecture">C. Neural network architecture</h3>
<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/171521307-7da18cd9-1669-4f0e-b311-7bea163738fd.png" width="100%" />
</div>

<p>모델의 모듈은 크게 4가지로 구성되어있습니다.</p>

<h4 id="module-1">Module 1</h4>
<p>Conv2D(kernel size: 1,32)는 256ms 윈도우 사이즈이며 224ms overlap됩니다.<br />
이 Conv2D는 temporal feature 추출할뿐 아니라 input data를 다른 주기로 나눌 수 있으며 temporal 차원을 줄일 수 있습니다. 또한 이 과정은 각각의 ERP구성을 적절한 spatial filter로 학습할 수 있습니다.<br />
이후 분포가 shift되는 것을 방지하기 위한 batch normalization (BN)와 linear activation function인 ELU를 사용해 negative value of loss가 되는 것을 방지했습니다.</p>

<h4 id="module-2">Module 2</h4>
<p>Module 2는 permute를 이용해 sptial feature를 추출했습니다.<br />
먼저 DepthwiseConv2D(kernel size: 60,1)로 각각의 spatial feature를 학습하기 위해 permute layer에서 eeg_channel x filter x period (60x8x25)로 차원을 변경합니다.<br />
이후 DepthwiseConv2D를 진행함으로써 25개의 spatial filter를 얻습니다. 다른 주기를 학습하는 각각의 spatial filter는 설계는 ERP의 phase-locked(위상 고정) 특성을 활용합니다.<br />
이 후 permute를 이용해 원래 차원으로 수정해준 수 Module 1과 마찬카지로 BN, ELU layer를 거칩니다.</p>

<h4 id="module-3">Module 3</h4>
<p>SeparableConv2D(kernel size: 1,9: Conv2D와 같지만 연산량을 줄여줌) temporal features를 추출합니다.
이 후 BN, ELU layer를 거치고 global average pooling layer를 이용해 차원을 줄이고 overfiting을 방지합니다.</p>

<h4 id="module-4">Module 4</h4>
<p>Module 4는 마지막에 2개의 값만 나오게 해주는  FC layer와 softmax를 이용해 두 classes에 대한 확률값을 반환해줍니다.</p>

<h3 id="d-training-settings-and-implementations">D. Training settings and implementations</h3>
<ul>
  <li>model의 모든 parameter는 Glorot Uniform method에 의해 초기화</li>
  <li>class의 불군형을 맞추기위해 class에 가중치를 부여함</li>
  <li>optimizer: Adam</li>
  <li>loss function: cross-entropy</li>
  <li>scheduler: 5 epoch마다 valid loss가 향상되지 않으면 lr를 반씩 줄임, 20 epoch동안 valid loss가 향상되지 않으면 학습 멈춤</li>
  <li>batchsize: 64</li>
  <li>cross-validation: 4 fold(4 session중 1개는 train, 1개는 valid, 2개는 test)</li>
</ul>

<h2 id="results">Results</h2>
<h3 id="a-classification-performance">A. Classification performance</h3>
<p>모델 성능 비교는 traditional methods(HDCA/SWFP), deep learning models (DeepConvNet/EEGNet)으로 진행됐습니다.</p>

<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/171528194-93b0234c-319a-4f31-852c-a7635ad188da.png" width="100%" />
</div>
<blockquote>
  <p>true positive rate (TPR),false positive rate (FPR), F1-Score and area under the
curve (AUC)</p>
</blockquote>

<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/171528384-2d04f66a-85f4-43f7-abc5-a426720b2105.png" width="100%" />
</div>
<blockquote>
  <p>parameter 수 비교</p>
</blockquote>

<h3 id="b-role-of-permute-layers">B. Role of permute layers</h3>

<p>논문에서 제시한 PLNet의 permute layer는 depthwise convolution이 서로 다른 periods에 대한 spatial filter를 학습할 수 있게 하기에 중요하다고 합니다.</p>

<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/171528438-b24a1702-826a-4081-9713-3eee762572a0.png" width="100%" />
</div>
<blockquote>
  <p>permute layer 추가/미추가 결과 비교</p>
</blockquote>

<h3 id="c-features-analysis">C. Features analysis</h3>
<p>PLNet으로 학습된 특징들을 시각화하기위해 topographies, saliency maps 두가지 방법으로 접근했습니다.</p>

<h4 id="1-topographies">1) topographies</h4>
<p>먼저 Spatial topographies를 사용하기 위해 25개의 spatial filter의 가중치 중에서 가장 discriminative한 특성을 보이는  9, 13, 17번쨰 filter를 시각화 했습니다.</p>
<blockquote>
  <p>9번째 filter: 256–512 ms<br />
13번째 filter: 384–640 ms<br />
17번째 filter: 512–768 ms</p>
</blockquote>

<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/171535058-30450548-34ef-42f8-b8d9-137333725164.png" width="80%" />
</div>
<p>특히 9번째 filter(256–512 ms)는 P300 신호이며 대부분의 subject들이 큰 가중치를 보였습니다.</p>

<h4 id="2-saliency-map">2) saliency map</h4>
<p>saliency map은 PLNet으로 학습된 temporal features를 분석하기 위한 방법입니다.</p>

<p>saliency map은 Backpropagation 알고리즘을 통해 input에 대한 모델 output의 기울기를 계산하여 얻어집니다.<br />
saliency map의 기울기 크기는 분류하기 위한 특징의 기여도를 나타냅니다.</p>

<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/171541047-e2622320-f625-4a43-aa06-fd745407d9b0.png" width="100%" />
</div>
<blockquote>
  <p>본 논문에선 Pz채널의 평균을 사용함</p>
</blockquote>

<p>결과를 보면 일반적으로 10Hz의 SSVEP의 특징을 보이고 N200, P300의 ERP 구성을 찾을 수 있었습니다.<br />
더 큰 기울기는 300–700 ms에 나타나며, 이는 패러다임에 의해 유발되는 P300 및 기타 이후 구성 요소에 해당합니다.<br />
대부분의 subject의 기울기에서 P100 및 N200과 같은 100~300ms 사이의 일부 ERP 구성 요소도 확인됩니다.</p>

<p class="box-note">결과적으로 PLNet이 ERP 구성 요소의 discriminative한 특징을 효과적으로 추출할수 있다는 것을 보여줍니다.</p>

<h2 id="discussion">Discussion</h2>
<p>PLNet의 Convolution은 temporal을 압축하고(Conv2d), 다른 주기를 바탕으로 spatial filter를 학습함(depthwise_Conv2d)으로써 ERP 구성 요소의 phase-locked(위상 고정) 특성 포착 할 수 있었습니다.</p>

<p>결론적으로 기존의 EEGNet 및 DeepConvNet과 같은 딥러닝 모델보다 우수한 성능을 얻었습니다.</p>
<blockquote>
  <p>FPR의 감소, PR, F1-Score, AUC 증가</p>
</blockquote>

<p>이후 PLNet이 phase-locked components를 기반으로 하는 패러다임에 적용되길 바라며 EEG연구에 reference가 될수도 있을것이라 하며 마무리 됩니디.</p>

<hr />

<h2 id="고찰">고찰</h2>
<p>제어분야(VR, Real Time)와 RSVP를 접목시킨다면, 집중해야하는 곳으 응시해 P300을 발생시켜 특정 task를 수행 시킬 수도 있을 것 같다.<br />
(eg. VR display에서 우측상단 모서리의 검정색 톱니바퀴를 응시하다가 갑자기 흰색 톱니바퀴가 등장할때 나오는 신호를 분류해 설정화면을 보여줌,
p300신호를 이용한 인지능력 활용등)</p>

<h6 id="reference">Reference</h6>
<ul>
  <li>https://pubmed.ncbi.nlm.nih.gov/34284365/</li>
</ul>

      </article>

      
        <div class="blog-tags">
          <span>Tags:</span>
          
            <a href="/tags#Brain Computer Interface">Brain Computer Interface</a>
          
        </div>
      

      

      
        <!-- Check if any share-links are active -->





      

      <ul class="pagination blog-pager">
        
        <li class="page-item previous">
          <a class="page-link" href="/2022-05-30-Artificial-Intelligence-for-the-Metaverse-A-Survey/" data-toggle="tooltip" data-placement="top" title="Review - Artificial Intelligence for the Metaverse - A Survey">&larr; Previous Post</a>
        </li>
        
        
        <li class="page-item next">
          <a class="page-link" href="/2022-06-07-The-Effect-of-Multisensory-Pseudo-Haptic-Feedback-on-Perception-of-Virtual-Weight/" data-toggle="tooltip" data-placement="top" title="Review - The Effect of Multisensory Pseudo-Haptic Feedback on Perception of Virtual Weight">Next Post &rarr;</a>
        </li>
        
      </ul>
      
  <div class="disqus-comments">
  <div class="comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
	  var disqus_shortname = 'beautiful-jekyll';
	  /* ensure that pages with query string get the same discussion */
	  var url_parts = window.location.href.split("?");
	  var disqus_url = url_parts[0];
	  (function() {
		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	  })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</div>
  
  

  


  



    </div>
  </div>
</div>


  <footer>
  <div class="container-md beautiful-jekyll-footer">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
      <ul class="list-inline text-center footer-links"><li class="list-inline-item">
    <a href="mailto:jerife@naver.com" title="Email me">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">Email me</span>
   </a>
  </li><li class="list-inline-item">
    <a href="https://github.com/jerife" title="GitHub">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">GitHub</span>
   </a>
  </li></ul>

      
      <p class="copyright text-muted">
      
        Jerife
        &nbsp;&bull;&nbsp;
      
      2022

      
        &nbsp;&bull;&nbsp;
        <span class="author-site">
          <a href="http://localhost:4000/">Jerife.github.io</a>
        </span>
      

      
      </p>
      <p class="theme-by text-muted">
        Powered by
        <a href="https://beautifuljekyll.com">Beautiful Jekyll</a>
      </p>
      </div>
    </div>
  </div>
</footer>


  
  
    
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin="anonymous"></script>


  
    
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


  
    
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


  



  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
      <script src="/assets/js/beautifuljekyll.js"></script>
    
  









</body>
</html>
