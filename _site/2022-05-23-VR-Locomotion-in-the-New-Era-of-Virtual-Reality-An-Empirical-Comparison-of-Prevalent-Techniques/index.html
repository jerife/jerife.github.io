<!DOCTYPE html>
<html lang="en">
<!-- Beautiful Jekyll 5.0.0 | Copyright Dean Attali 2020 -->
<head></head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
  }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!--$f(x) = x^2$->
  

  

  

  <title>Review - VR Locomotion in the New Era of Virtual Reality An Empirical Comparison of Prevalent Techniques</title>

  
  <meta name="author" content="Jerife">
  

  <meta name="description" content="Virtual Reality Locomotion">

  

  

  
  <link rel="alternate" type="application/rss+xml" title="Jerife" href="http://localhost:4000/feed.xml">
  

  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-H3TE8W3M78"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-H3TE8W3M78');
</script>

  

  

  


  
    
      
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">


    
      
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">


    
  

  
    
      <link rel="stylesheet" href="/assets/css/bootstrap-social.css">
    
      <link rel="stylesheet" href="/assets/css/beautifuljekyll.css">
    
  

  

  
  
  

  

  
  <meta property="og:site_name" content="Jerife">
  <meta property="og:title" content="Review - VR Locomotion in the New Era of Virtual Reality An Empirical Comparison of Prevalent Techniques">
  <meta property="og:description" content="Virtual Reality Locomotion">

  
  <meta property="og:image" content="http://localhost:4000/assets/img/avatar-icon.png">
  

  
  <meta property="og:type" content="article">
  <meta property="og:article:author" content="Jerife">
  <meta property="og:article:published_time" content="2022-05-23T00:00:00+09:00">
  <meta property="og:url" content="http://localhost:4000/2022-05-23-VR-Locomotion-in-the-New-Era-of-Virtual-Reality-An-Empirical-Comparison-of-Prevalent-Techniques/">
  <link rel="canonical" href="http://localhost:4000/2022-05-23-VR-Locomotion-in-the-New-Era-of-Virtual-Reality-An-Empirical-Comparison-of-Prevalent-Techniques/">
  

  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:site" content="@">
  <meta name="twitter:creator" content="@">

  <meta property="twitter:title" content="Review - VR Locomotion in the New Era of Virtual Reality An Empirical Comparison of Prevalent Techniques">
  <meta property="twitter:description" content="Virtual Reality Locomotion">

  
  <meta name="twitter:image" content="http://localhost:4000/assets/img/avatar-icon.png">
  

  


  

  
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/log.ico/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/log.ico/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/log.ico/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/log.ico/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/log.ico/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/log.ico/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/log.ico/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/log.ico/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/log.ico/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/log.ico/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/log.ico/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/log.ico/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/log.ico/favicon-16x16.png">
  <link rel="manifest" href="/assets/log.ico/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/log.ico/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
</head>

<body>

  


  <nav class="navbar navbar-expand-xl navbar-light fixed-top navbar-custom top-nav-regular"><a class="navbar-brand" href="http://localhost:4000/">Jerife</a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="main-navbar">
    <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="/tags">Records</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="/aboutme">About Me</a>
          </li>
        <li class="nav-item">
          <a class="nav-link" id="nav-search-link" href="#" title="Search">
            <span id="nav-search-icon" class="fa fa-search"></span>
            <span id="nav-search-text">Search</span>
          </a>
        </li></ul>
  </div>

  

  
    <div class="avatar-container">
      <div class="avatar-img-border">
        <a href="http://localhost:4000/">
          <img alt="Navigation bar avatar" class="avatar-img" src="/assets/img/avatar-icon.png" />
        </a>
      </div>
    </div>
  

</nav>



<div id="beautifuljekyll-search-overlay">

  <div id="nav-search-exit" title="Exit search">✕</div>
  <input type="text" id="nav-search-input" placeholder="Search">
  <ul id="search-results-container"></ul>
  
  <script src="https://unpkg.com/simple-jekyll-search@latest/dest/simple-jekyll-search.min.js"></script>
  <script>
    var searchjson = '[ \
       \
        { \
          "title"    : "Review -A Hybrid Speller Design Using Eye Tracking and SSVEP Brain–Computer Interface", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-07-13-A-Hybrid-Speller-Design-Using-Eye-Tracking-and-SSVEP-Brain-Computer-Interface/", \
          "date"     : "July 13, 2022" \
        }, \
       \
        { \
          "title"    : "Review - An EEG/EMG/EOG-Based Multimodal Human-Machine Interface to Real-Time Control of a Soft Robot Hand", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-07-04-An-EEG-EMG-EOG-Based-Multimodal-Human-Machine-Interface-to-Real-Time-Control-of-a-Soft-Robot-Hand/", \
          "date"     : "July  4, 2022" \
        }, \
       \
        { \
          "title"    : "Review - Motion Imagery-BCI Based on EEG and Eye Movement Data Fusion", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-07-03-Motion-Imagery-BCI-Based-on-EEG-and-Eye-Movement-Data-Fusion/", \
          "date"     : "July  3, 2022" \
        }, \
       \
        { \
          "title"    : "Review - Hybrid EEG-EOG-based BCI system for Vehicle Control", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-06-20-Hybrid-EEG-EOG-based-BCI-system-for-Vehicle-Control/", \
          "date"     : "June 20, 2022" \
        }, \
       \
        { \
          "title"    : "Review - An autonomous hybrid brain-computer interface system combined with eye-tracking in virtual environment", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-06-19-An-autonomous-hybrid-brain-computer-interface-system-combined-with-eye-tracking-in-virtual-environment/", \
          "date"     : "June 19, 2022" \
        }, \
       \
        { \
          "title"    : "Review - User-defined walking-in-place gestures for VR locomotion", \
          "category" : "Virtual Reality", \
          "url"      : "/2022-06-13-User-defined-walking-in-place-gestures-for-VR-locomotion/", \
          "date"     : "June 13, 2022" \
        }, \
       \
        { \
          "title"    : "Review - A Sliding Window Common Spatial Pattern for Enhancing Motor Imagery Classification in EEG-BCI", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-06-08-A-Sliding-Window-Common-Spatial-Pattern-for-Enhancing-Motor-Imagery-Classification-in-EEG-BCI/", \
          "date"     : "June  8, 2022" \
        }, \
       \
        { \
          "title"    : "Review - The Effect of Multisensory Pseudo-Haptic Feedback on Perception of Virtual Weight", \
          "category" : "Virtual Reality", \
          "url"      : "/2022-06-07-The-Effect-of-Multisensory-Pseudo-Haptic-Feedback-on-Perception-of-Virtual-Weight/", \
          "date"     : "June  7, 2022" \
        }, \
       \
        { \
          "title"    : "Review - A deep learning method for single-trial EEG classification in RSVP task based on spatiotemporal features of ERPs", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-06-02-A-deep-learning-method-for-single-trial-EEG-classification-in-RSVP-task-based-on-spatiotemporal-features-of-ERPs/", \
          "date"     : "June  2, 2022" \
        }, \
       \
        { \
          "title"    : "Review - Artificial Intelligence for the Metaverse - A Survey", \
          "category" : "Virtual Reality", \
          "url"      : "/2022-05-30-Artificial-Intelligence-for-the-Metaverse-A-Survey/", \
          "date"     : "May 30, 2022" \
        }, \
       \
        { \
          "title"    : "Review - A hybrid BCI-controlled smart home system combining SSVEP and EMG for individuals with paralysis", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-05-25-A-hybrid-BCI-controlled-smart-home-system-combining-SSVEP-and-EMG-for-individuals-with-paralysis/", \
          "date"     : "May 25, 2022" \
        }, \
       \
        { \
          "title"    : "Review - An integrated deep learning model for motor intention recognition of multi-class EEG Signals in upper limb amputees", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-05-24-An-integrated-deep-learning-model-for-motor-intention-recognition-of-multi-class-EEG-Signals-in-upper-limb-amputees/", \
          "date"     : "May 24, 2022" \
        }, \
       \
        { \
          "title"    : "Review - VR Locomotion in the New Era of Virtual Reality An Empirical Comparison of Prevalent Techniques", \
          "category" : "Virtual Reality", \
          "url"      : "/2022-05-23-VR-Locomotion-in-the-New-Era-of-Virtual-Reality-An-Empirical-Comparison-of-Prevalent-Techniques/", \
          "date"     : "May 23, 2022" \
        }, \
       \
        { \
          "title"    : "Review - Brain Controlled Wheelchairs A Robotic Architecture", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-05-18-Brain-Controlled-Wheelchairs-A-Robotic-Architecture/", \
          "date"     : "May 18, 2022" \
        }, \
       \
        { \
          "title"    : "Review - Robust Classification of EEG Signal for Brain Computer Interface", \
          "category" : "Brain Computer Interface", \
          "url"      : "/2022-05-17-Robust-classification-of-EEG-signal-for-brain-computer-interface/", \
          "date"     : "May 17, 2022" \
        }, \
       \
        { \
          "title"    : "Introduce to LUKE", \
          "category" : "Natural Language Processing", \
          "url"      : "/2022-01-03-luke/", \
          "date"     : "January  3, 2022" \
        }, \
       \
        { \
          "title"    : "2021년 한 해를 돌아보는 회고록", \
          "category" : "Diary", \
          "url"      : "/2021-12-31-2021end/", \
          "date"     : "December 31, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to ELECTRA", \
          "category" : "Natural Language Processing", \
          "url"      : "/2021-12-11-electra/", \
          "date"     : "December 11, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to RoBERTa", \
          "category" : "Natural Language Processing", \
          "url"      : "/2021-12-07-roberta/", \
          "date"     : "December  7, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to BERT", \
          "category" : "Natural Language Processing", \
          "url"      : "/2021-11-19-bert/", \
          "date"     : "November 19, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Transformer", \
          "category" : "Natural Language Processing", \
          "url"      : "/2021-11-17-transformer/", \
          "date"     : "November 17, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Attention Mechanism", \
          "category" : "Natural Language Processing", \
          "url"      : "/2021-11-16-attention/", \
          "date"     : "November 16, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to EfficientDet", \
          "category" : "Computer VisionObject Detection", \
          "url"      : "/2021-11-15-efficientdet/", \
          "date"     : "November 15, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to EfficientNet", \
          "category" : "Computer Vision", \
          "url"      : "/2021-10-28-efficientnet/", \
          "date"     : "October 28, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Yolo v3", \
          "category" : "Computer VisionObject Detection", \
          "url"      : "/2021-10-09-yolov3/", \
          "date"     : "October  9, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Faster R-CNN", \
          "category" : "Computer VisionObject Detection", \
          "url"      : "/2021-09-12-fasterrcnn/", \
          "date"     : "September 12, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Fast R-CNN", \
          "category" : "Computer VisionObject Detection", \
          "url"      : "/2021-09-10-fastrcnn/", \
          "date"     : "September 10, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to R-CNN", \
          "category" : "Computer VisionObject Detection", \
          "url"      : "/2021-07-25-rcnn/", \
          "date"     : "July 25, 2021" \
        }, \
       \
        { \
          "title"    : "Intriduce to ARIMA Model", \
          "category" : "Time Series", \
          "url"      : "/2021-06-26-arima/", \
          "date"     : "June 26, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to Seq2Seq", \
          "category" : "Natural Language ProcessingTime Series", \
          "url"      : "/2021-06-08-seq2seq/", \
          "date"     : "June  8, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to LSTM", \
          "category" : "Natural Language ProcessingTime Series", \
          "url"      : "/2021-06-06-lstm/", \
          "date"     : "June  6, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to RNN", \
          "category" : "Natural Language ProcessingTime Series", \
          "url"      : "/2021-06-05-rnn/", \
          "date"     : "June  5, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to DenseNet", \
          "category" : "Computer Vision", \
          "url"      : "/2021-05-12-densenet/", \
          "date"     : "May 12, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to ResNet", \
          "category" : "Computer Vision", \
          "url"      : "/2021-05-11-resnet/", \
          "date"     : "May 11, 2021" \
        }, \
       \
        { \
          "title"    : "Introduce to CNN", \
          "category" : "Computer Vision", \
          "url"      : "/2021-05-10-cnn/", \
          "date"     : "May 10, 2021" \
        }, \
       \
        { \
          "title"    : "To start blog with Github", \
          "category" : "Diary", \
          "url"      : "/2021-04-27-first/", \
          "date"     : "April 27, 2021" \
        }, \
       \
       \
        { \
          "title"    : "About me", \
          "category" : "page", \
          "url"      : "/aboutme/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "All Records", \
          "category" : "page", \
          "url"      : "/tags/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page2/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page3/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page4/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page5/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page6/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page7/", \
          "date"     : "January 1, 1970" \
        }, \
       \
        { \
          "title"    : "Jerife Blog", \
          "category" : "page", \
          "url"      : "/page8/", \
          "date"     : "January 1, 1970" \
        } \
       \
    ]';
    searchjson = JSON.parse(searchjson);

    var sjs = SimpleJekyllSearch({
      searchInput: document.getElementById('nav-search-input'),
      resultsContainer: document.getElementById('search-results-container'),
      json: searchjson
    });
  </script>
</div>





  <!-- TODO this file has become a mess, refactor it -->







<header class="header-section ">

<div class="intro-header no-img">
  <div class="container-md">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
        <div class="post-heading">
          <h1>Review - VR Locomotion in the New Era of Virtual Reality An Empirical Comparison of Prevalent Techniques</h1>
          
            
              <h2 class="post-subheading">Virtual Reality Locomotion</h2>
            
          

          
            <span class="post-meta">Posted on May 23, 2022</span>
            
            
          
        </div>
      </div>
    </div>
  </div>
</div>
</header>





<div class=" container-md ">
  <div class="row">
    <div class=" col-xl-8 offset-xl-2 col-lg-10 offset-lg-1 ">

      
        
        
        

        <div id="header-gh-btns">
          
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=jerife&repo=jerife.github.io&type=star&count=true" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=jerife&type=follow&count=true" frameborder="0" scrolling="0" width="220px" height="20px"></iframe>
              
            
          
        </div>
      

      

      <article role="main" class="blog-post">
        <div align="center"><h2>VR Locomotion in the New Era of Virtual Reality- An Empirical Comparison of Prevalent Techniques 논문 리뷰</h2></div>
<!--break-->

<hr />

<p><br /></p>

<h2 id="abstract">ABSTRACT</h2>
<p>해당 Article은 3가지의 VR Locomotion techniques을 mixed methods approach에 기반한 사용자의 경험적인 요소(UX)를 평가합니다.</p>

<p>위 실험을 통해 아래와 같은 결과를 도출합니다.</p>
<blockquote>
  <p>(i) walking-in-place: 높은 몰입성을 보이지만 신체적으로 쉽게 지침<br />
(ii) controller/joystick: 친숙한 기법이기 때문에 쉽게 조작 가능<br />
(iii) teleportation: 빠르게 이동할 수 있지만 시각적으로 사용자의 몰입성이 떨어짐</p>
</blockquote>

<h2 id="introduction">INTRODUCTION</h2>
<p>논문의 목적은 널리 사용되는 VR Locomotion를 비교하고 경험적인 평가 연구를 제시합니다. 궁극적으론 새로운 VR Locomotion의 기술을 개발하고 연구에 기여하기 위함입니다.</p>

<h2 id="background">BACKGROUND</h2>
<p>위 논문은 이전 VR Locomotion에 대해 평가, 비교한 논문들을 기반으로 VR Locomotion을 실험하고 평가했습니다.</p>

<p>해당 Chapter에는 각 VR Locomotion와 이를 다룬 논문들이 기재되어 있으니 참고하시길 바랍니다.</p>

<h2 id="prevalent-vr-locomotion-techniques">Prevalent VR Locomotion Techniques</h2>
<p>시작에 앞서 가장 널리 사용되고 있는 4가지 VR Locomotion를 언급합니다.</p>

<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/169730451-4f004639-e259-4045-819a-62374658e9a7.png" width="100%" />
</div>

<blockquote>
  <p>(i) Motion-based: 신체를 이용해 continuous하게 interact함 <br />
(ii) Room-scale-based: Motion-based와 같게 interact하지만 실제 환경의 규모와 사이즈에 제한을 받음<br />
(iii) Controller-based: Controller를 기반으로 continuous하게 interact함 <br />
(iv) Teleportation-based: Controller로 순간이동을 하면서 discrete하게 interact함 <br /></p>
</blockquote>

<p>원래 가장 널리 사용되는 4가지 VR Locomotion지만, <br />
(ii) Room-scale-based의 경우 실제 환경의 물리적 한계요소가 있기 때문에 VR Space기반인 나머지 3가지를 이용해 비교, 평가 합니다.</p>

<h2 id="methodology">METHODOLOGY</h2>
<p>본 연구는 널리 보급된 세 가지 VR Locomotion을 평가하고 향후 관련 설계에 사용할 수 있는 피드백을 받아 어떤 경험적 요인, 경험적 품질 및 시스템 특징이 VR 이동과 가장 관련이 있는지 조사합니다.</p>

<h3 id="a-materials">A. Materials</h3>
<h4 id="vr-locomotion-techniques">VR Locomotion Techniques</h4>
<ul>
  <li>HTC Vive headset</li>
  <li>SteamVR SDK for Unreal Engine 4 by Epic Games</li>
  <li>Body tracking할 수 있는 적외선 sensors</li>
  <li>Body tracking할 수 있는 HTC Vive tracker</li>
  <li>walking-in-place and controller/joystick 의 경우 speeds를 (1~4-3m/s)로 제한</li>
</ul>

<h6 id="i-walking-in-place">(i) Walking-in-place</h6>
<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/169732803-56492366-e18d-493a-b5ce-c5b4f4c55bf6.png" width="50%" />
</div>
<p>오른쪽 발에 HTC Vive tracker 부착, HMD를 기준으로 화면이 시각적으로 보여짐 방향을 바꾸기 위해선 몸을 돌아 움직어여함</p>

<h6 id="ii-controllerjoystick">(ii) Controller/joystick</h6>
<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/169733447-a4badc37-83b6-4ae7-9037-49b8fe2766b4.png" width="50%" />
</div>
<p>Walking-in-place와 방식은 같지만 컨트롤러를 이용해 움직이는 차이점이 있습니다.</p>

<h6 id="iii-teleportation">(iii) Teleportation</h6>
<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/169733619-7fb807be-6cc4-44a3-9c71-04ea8d99c0f7.png" width="50%" />
</div>
<p>Teleportation의 경우 버튼을 누르고 화면에 보이는 mark된 위치로 이동하는 mechanism입니다.</p>

<h4 id="questionnaires-and-interview">Questionnaires and Interview</h4>
<p>데이터 수집 시작 단계에 Subjects의 age, gender, frequency of VR use와 같은 기본적인 정보를 수집했습니다.</p>

<p>연구의 데이터는 Game Experience Questionnaire, System Usability Scale questionnaire, Semistructured interview로 수집되고 평가 되었습니다.</p>

<h6 id="i-game-experience-questionnaire-geq">(i) Game Experience Questionnaire (GEQ)</h6>
<p>사용자 경험 설문이며 넓은 범위의 요소에 좋은 신뢰성을 보이기 때문에 다양한 domain에서 사용되었습니다. 설문은 총 16문항으로 0~5점까지 부여될 수 있습니다.</p>

<p>VR 도메인에선 navigation, locomotion, haptic interaction, VR learning, cyberpsychology, VR gaming 등에 사용되었습니다.</p>

<p>기술 평가의 요소로는 Competence, Sensory, Imaginative Immersion, Flow, Tension, Challenge, Negative Affect, Positive Affect, Tiredness등이 가 있습니다.</p>

<h6 id="ii-system-usability-scale-sus">(ii) System Usability Scale (SUS)</h6>
<p>SUS는 참여자와 연구자의 생산품과 서비스의 주관적인 사용성을 측정할 수 있는 기법입니다. 또한 소수의 subject에 견고한 결과를 낼 수 있다는 장점이 있습니다.</p>

<p>VR 도메인에선 VR rehabilitation and health services, VR learning, VR training 등에 사용됐습니다.</p>

<p>SUS는 10개의 문항으로 0~100점까지 부여될 수 있습니다. 점수는 형용적으로(good, ok, bad, etc)등으로 표현될 수 있으며 A~F로 매핑할 수 있습니다.</p>

<h6 id="iii-semistructured-interviews">(iii) Semistructured interviews</h6>
<p>semistructured interview는 subject들에게 각 VR Locomotion에 장단점이나 그 이유등을 물어보고 comment를 받는 과정입니다.</p>

<h3 id="b-environment">B. Environment</h3>
<p>연구는 ‘Simple Town’라는 가상환경에서 진행되었습니다.</p>

<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/169740146-1f3d614e-70cd-4112-9382-f0d01b36ee17.png
" width="50%" />
</div>
<p>Subject는 특정장소를 다녀야하는 task를 수행해야합니다. (eg. 먼저 자동차 수리점을 들렸다가 영화관을 가세요…) <br />
사진속에선 빨,파,초 3가지 task이며 각 task는 다른 VR Locomotion 기술을 사용해 실험합니다.<br />
각 task는 7~15분 동안만 진행할 수 있습니다.</p>

<h3 id="c-procedure">C. Procedure</h3>
<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/169748562-84513fba-44ed-44a4-9fdb-320f60b316f7.png" width="100%" />
</div>
<p>먼저 Subject에게 연구에 관한 정보를 숙지시킨 뒤, 그들의 기본적인 정보 및 VR 경험에 관한 설문을 진행합니다.<br />
그 후 Subject에게 VR을 경험할 수 있는 시간(연습시간) 5~7분정도를 제공한 후 task가 실행됩니다. 실험중에 Subject는 구두로 feedback및 인터뷰를 위한 메모를 할 수 있습니다.<br />
한 task가 종료되고 SUS and GEQ 설문을 시작하고 5분정도 휴식 후, 다음 task를 진행됩니다. 3 task가 모두 끝난 후 Subject는 Semistructured interview를 진행합니다.</p>

<h3 id="d-statistical-analysis">D. Statistical Analysis</h3>
<p>모든 데이터는 SPSS를 이용해 분석되었습니다. 유의 수준은 $p$ &lt; 0.05로 설정되었습니다.
참가자의 GEQ, SUS 값을 분석하기위해 기술분석이 사용되었습니다.</p>

<ul>
  <li>프리드먼 검정으로 두 값의 차이를 탐지합니다.</li>
  <li>post-hoc, pair-wise 분석을 위해 Wilcoxon signed rank test이 적용됩니다.</li>
  <li>인터뷰 데이터는 핵심 개념, 주제 및 아이디어가 식별되어져 open, axial 코딩으로 NVivo로 분석됩니다.</li>
</ul>

<h3 id="e-results">E. Results</h3>
<h4 id="game-experience-questionnaire-geq">Game Experience Questionnaire (GEQ)</h4>
<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/169748626-932294c0-56e4-4b5f-b862-23cbf4ef7c40.png" width="100%" />
</div>

<p>위 표는 Wilcoxon signed rank test를 사용한 GEQ 점수의 post-hoc 분석 결과를 제시합니다.</p>

<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/169751396-adb20dfc-fe92-448b-92e3-2a451c4ac662.png" width="100%" />
</div>

<p>위 도표는 GEQ 설문지의 평균 값을 의미합니다.</p>

<h4 id="system-usability-scale-sus">System Usability Scale (SUS)</h4>
<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/169752331-588c5f47-f655-41b6-865a-19863180ab53.png" width="100%" />
</div>

<p>SUS에서 얻어진 결과를 형용된 평가와 점수를 기반으로 묘사해놓은 표입니다.</p>

<p>post-hoc 분석은 WIP and Controller (𝑍 = −3.833, 𝑝 &lt; 0.001), WIP and Teleportation (𝑍 = −3.393, 𝑝 = 0.001)
두 케이스의  pair-wise 분석에서 유의미한 것을 확인할 수 있으며, WIP는 다른 두 기술보다 낮은 SUS 값을 띄었습니다.</p>

<h4 id="semistructured-interviews">Semistructured interviews</h4>
<div align="center">
    <img src="https://user-images.githubusercontent.com/68190553/169753791-35497b25-142a-47b6-8a62-18297994089f.png" width="100%" />
</div>

<p>WIP의 경우 실제로 움직이는 것에 높은 몰입도를 제공했으며 운동, 재미, 오락등의 특징성이 있음을 발견하기도 했습니다.<br />
반면 움직이는 것이 성가시다는 의견과 시각적인 제한으로 인한 두려움, 멀미 유발등의 의견도 있었습니다.</p>

<p>Controller/Joystick의 경우 친숙하고 직관적이고 편하다는 의견이 있었으며 조작법을 빠르게 숙지할 뿐아니라 만족스러운 몰입도를 제공한다는 의견도 있었습니다.</p>

<p>Teleportation의 경우 몰입도가 가장 낮다고 보고되었습니다. 이유로는 시각적으로 점프와 불연속적으로 움직이기 때문입니다. 또한 텔레포트 이후의 화면은 시각적으로도 부담이 된다고 합니다. <br />
하지만 빠르고 효율적으로 이동할 수 있다는 장점과 숙지하는데 어렵지 않다는 의견이 보고됐습니다.</p>

<h2 id="discussion">DISCUSSION</h2>
<h3 id="a-walking-in-place">A. Walking-in-Place</h3>
<p>WIP(Walking-in-Place)는 GEQ의 Tension, Challenge, Negative Affect, Tiredness에서 높은 값을 얻었으며 SUS의 값이 낮았습니다.</p>

<p>Subjects는 두가지의 정반대 의견을 냈습니다.</p>
<ol>
  <li>반복적으로 움직이는 것은 지루함을 초래하며 HMD으로 인해 앞이 보이지 않는 상황에서 부딪칠지도 모른다는 두려움이 있음</li>
  <li>VR 컨텐츠에 더욱 흥미로운 요소가 추가된 것 같음</li>
</ol>

<p>반복적으로 움직이는 것은 지루함을 초래하는 것은 이전 연구들과 공통적으로 발견된 결과이지만, 이번 실험을 통해 ‘HMD으로 인해 앞이 보이지 않는 상황에서 부딪칠지도 모른다는 두려움이 있음’라는 새로운 발견이 있었습니다.</p>

<p>궁극적으로 WIP는 VR과 강한 연결성을 띄우고 있으며, User가 사전에 체력소모가 있다는 것을 알고 시작한다면 흥미를 느낄 수 있을 것이라 했습니다.<br />
추가적으로 운동이나 게임같은 행동이 필요한 콘텐츠에 접목시킬경우 큰 장점을 발휘할 수 있을 것이라는 결론을 제시합니다.</p>

<h3 id="b-controllerjoystick">B. Controller/Joystick</h3>
<p>Controller/Joystick은 GEQ의 Competence, Immersion,
Flow, Positive Affect에서 중간~높은 값을 얻었으며 최상의 SUS의 값을 얻었습니다.</p>

<p>이유를 분석해본 결과 조작이 쉬우며 금방 숙련될 수 있기 때문입니다. 또한 높은 편리성을 보여주지만 GEQ의 Tension, Negative Affect, Tiredness에서 낮은 값을 얻었습니다.</p>

<h3 id="c-teleportation">C. Teleportation</h3>
<p>Teleportation의 경우 조작이 쉽고 효과적이라는 결과가 도출됐습니다.</p>

<p>하지만 인터뷰결과를 통해 멀미가 심하다는 부정적인 인식이 있었으며 그 이유로는 점프로 날아가는 모션이나 갑자기 화면이 바뀌어 시각적으로 부담스럽기 때문이었습니다.</p>

<p>GEQ Immersion and Flow에서 낮은 값을 부여받았으며 중간정도의 Challenge, 중간~낮음정도의 Negative Affect, Tiredness는 상호작용과 관련되 문제일 수도 있음을 제시했습니다.</p>

<h2 id="conclusion">CONCLUSION</h2>
<ol>
  <li>본 연구는 경험적으로 사용자 중심의 관점에서 각 VR Locomotion의 속성을 문서화하고,</li>
  <li>이것이 미래 VR Locomotion 연구,개발에 영향이 갈수 있도록 의미를 제시하고,</li>
  <li>사용자가 상호작용하면서 중요하게 여겨지는 4가지 dimensions을 비교하는 것에 집중 되었습니다.
    <blockquote>
      <p>4 dimensions: Immersion, Ease-of-use and mastering, Competence and sense of effectiveness, Psychophysical discomfort</p>
    </blockquote>
  </li>
</ol>

<p>논문은 향후엔 각 VR Locomotion의 개발과 발전에 대해 다룰 것이며, 4가지 dimensions을 측정할 수 있는 더 나아가 연구 툴 개발을 위해 연구할 것이라며 마무리됩니다.</p>

<hr />

<h2 id="고찰">고찰</h2>
<p>3가지 VR Locomotion 들은 각각의 Trade-off한 점이 있으며 그럼에도 가장 고전적인 방법중 하나인 Controller/Joystick가 가장 좋은 SUS 결과를 내는 것은 아직 VR Locomotion에 혁명적인 기술이 없기 때문이며 더욱이 BCI와 VR을 접목시키는 것이 필요하다고 생각이 들었다.</p>

<h6 id="reference">Reference</h6>
<ul>
  <li>https://www.hindawi.com/journals/ahci/2019/7420781/</li>
</ul>

      </article>

      
        <div class="blog-tags">
          <span>Tags:</span>
          
            <a href="/tags#Virtual Reality">Virtual Reality</a>
          
        </div>
      

      

      
        <!-- Check if any share-links are active -->





      

      <ul class="pagination blog-pager">
        
        <li class="page-item previous">
          <a class="page-link" href="/2022-05-18-Brain-Controlled-Wheelchairs-A-Robotic-Architecture/" data-toggle="tooltip" data-placement="top" title="Review - Brain Controlled Wheelchairs A Robotic Architecture">&larr; Previous Post</a>
        </li>
        
        
        <li class="page-item next">
          <a class="page-link" href="/2022-05-24-An-integrated-deep-learning-model-for-motor-intention-recognition-of-multi-class-EEG-Signals-in-upper-limb-amputees/" data-toggle="tooltip" data-placement="top" title="Review - An integrated deep learning model for motor intention recognition of multi-class EEG Signals in upper limb amputees">Next Post &rarr;</a>
        </li>
        
      </ul>
      
  <div class="disqus-comments">
  <div class="comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
	  var disqus_shortname = 'beautiful-jekyll';
	  /* ensure that pages with query string get the same discussion */
	  var url_parts = window.location.href.split("?");
	  var disqus_url = url_parts[0];
	  (function() {
		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	  })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</div>
  
  

  


  



    </div>
  </div>
</div>


  <footer>
  <div class="container-md beautiful-jekyll-footer">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
      <ul class="list-inline text-center footer-links"><li class="list-inline-item">
    <a href="mailto:jerife@naver.com" title="Email me">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">Email me</span>
   </a>
  </li><li class="list-inline-item">
    <a href="https://github.com/jerife" title="GitHub">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">GitHub</span>
   </a>
  </li></ul>

      
      <p class="copyright text-muted">
      
        Jerife
        &nbsp;&bull;&nbsp;
      
      2022

      
        &nbsp;&bull;&nbsp;
        <span class="author-site">
          <a href="http://localhost:4000/">Jerife.github.io</a>
        </span>
      

      
      </p>
      <p class="theme-by text-muted">
        Powered by
        <a href="https://beautifuljekyll.com">Beautiful Jekyll</a>
      </p>
      </div>
    </div>
  </div>
</footer>


  
  
    
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin="anonymous"></script>


  
    
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


  
    
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


  



  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
      <script src="/assets/js/beautifuljekyll.js"></script>
    
  









</body>
</html>
