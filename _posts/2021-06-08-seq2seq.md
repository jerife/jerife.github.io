---
layout: post 
title: Introduce to Seq2Seq
subtitle: Seq2Seq의 Encoder / Decoder
gh-repo: jerife/jerife.github.io
gh-badge: [star, follow]
tags: [Natural Language Processing]
comments: true
excerpt_separator: <!--break-->
---
<div align=center><h1>Seq2Seq 이해하기</h1></div>
<!--break-->

----

 <br/>
# Seq2Seq란?
###### Seq2Seq는 Sequence to Sequence의 약자로써, 시퀀스 데이터(언어, 시계열 데이터 등)를 또 다른 시퀀스 데이터로 변환해주는 모델입니다. <br/> <br/>
###### Seq2Seq 모델은 RNN모델(RNN, LSTM, GRU)등을 순환성을 기반으로 사용 되기에 [[RNN(Recurrent Neural Network) 이해하기](https://jerife.github.io/2021-06-05-rnn/)] | [[LSTM(Long Short-Term Memory) 이해하기](https://jerife.github.io/2021-06-06-lstm/)] 부분을 먼저 학습하셔야 합니다. <br/> <br/>
![seq2seq_gif_1](https://user-images.githubusercontent.com/68190553/121118577-0ebd6280-c855-11eb-8717-5a1b232331ee.gif){: .mx-auto.d-block :} <br/>
######  Seq2Seq 모델은 보이는 움짤과 같이 크게 **인코더 (Encoder)** 부분과 **디코더 (Decoder)** 부분으로 나눌 수 있습니다. <br/>
###### 간단하게 인코더는 문자를 데이터로 변환시키고, 디코더는 데이터를 문자로 변환시키는 역할을 합니다. <br/> <br/>

##  [RNN of Seq2Seq]
###### 여기 Seq2Seq의 Encoder와 Decoder에선 RNN 기반 모델들을 (RNN, LSTM, GRU) 사용합니다. 이 글에선 LSTM 모델을 사용한다 가정하겠습니다. <br/> <br/>
![lstm_img_4](https://user-images.githubusercontent.com/68190553/121049358-97ef7d80-c7f2-11eb-8cf4-83117dffe5ba.png){: .mx-auto.d-block :} <br/>
###### LSTM모델은 시간에 따른 데이터를 순환 시켜주는 "ht" 값과 / 중요한 데이터는 기억하고, 아닌 데이터는 잊는 기억셀 "Ct"가 있습니다. 이 두 값은 다음셀로 계속 사용전달 되어, 다음셀에 영향을 줍니다. <br/> <br/>
###### 이렇게 다음 층으로 계속 전달 되는 층을 **HIdden state** 라고도 부릅니다. <br/>

## [Seq2Seq Architecture]
###### Seq2Seq에서 사용 될 RNN모델을 정했기에 이제 Encoder / Decoder 와 이 둘을 이어주는 Context(문맥) 부분을 이해해보겠습니다.
![image](https://user-images.githubusercontent.com/68190553/121048577-e2bcc580-c7f1-11eb-9c39-2cb0f717ce2d.gif){: .mx-auto.d-block :} 
#### [1] Encoder<br/>
<img width="434" alt="seq2seq_img_2" src="https://user-images.githubusercontent.com/68190553/121124975-c0ae5c00-c860-11eb-9e27-ed281412fcf8.png">{: .mx-auto.d-block :}<br/>
###### Encoder부분을 보면 "je suis étudiant" 라는 문장이 Word level로(단어마다) RNN모델에 한개씩 들어가는 것을 알 수 있습니다. <br/> <br/>
###### 셀에 단어가 들어갈때 마다 **HIdden state**(LSTM의 기억셀 Ct와, 결과값 ht) 값이 나와서 다음셀에 영향을 주는 것을 볼 수 있습니다. <br/> <br/>
###### 이 후 마지막 셀에 "étudiant" 단어가 들어가는 순간 **HIdden state**값이 나오고 그 값이 Decoder에 들어가는 것을 볼 수 있습니다. 우리는 Encoder부분의 마지막 셀에서 나오는 HIdden state를 **Context Vector**(문맥)이라고도 부릅니다. <br/> <br/>

#### [2] Context Vector<br/>
<img width="27" alt="seq2seq_img_4" src="https://user-images.githubusercontent.com/68190553/121125066-e2a7de80-c860-11eb-8fd7-20e3e2ebefb5.png">{: .mx-auto.d-block :}<br/>
###### **Context Vector**(문맥)으로 불리는 Encoder부분의 마지막 셀에서 나오는 HIdden state에 대해서 추가적인 설명을 하겠습니다. <br/> <br/>
###### Context Vector는 입력값("je suis étudiant")의 모든 정보를 모아 놓은 동시에, **고정된 크기의 벡터**이기도 합니다. <br/> <br/>
###### 고정된 크기의 벡터는 많은양의 데이터도 꾹꾹 눌러서 압축시켜야하기 떄문에, 정보 손실률이 있다는 단점이 있지만, 차 후 **Attention Mechanism**을 통해 단점을 해결할 수 있게 됩니다. 이 글에선 Attention Mechanism에 대해선 다루지 않겠습니다. 

#### [3] Decoder<br/>
<img width="417" alt="seq2seq_img_3" src="https://user-images.githubusercontent.com/68190553/121125051-db80d080-c860-11eb-9b1c-038c2df283bc.png">{: .mx-auto.d-block :}<br/>
###### Decoder도 Encoder과 마찬가지로 정보를 받아, RNN을 통해 결과를 예측하는 것 까지는 같습니다.<br/>
###### Decoder는 유일한 정보인 Context Vector만을 정보로 받아 "i am a student"와 같은 결과를 출력합니다. <br/> <br/>

---

## [Seq2Seq 개선]
###### Seq2Seq 개선하는 방법 중 하나는 위에서 언급한 Attention Mechanism이 가장 인상 깊겠지만, 그전에 간단한 방법으로 개선하는 법을 언급하겠습니다. <br/> <br/>
######  => 입력데이터의 순서를 뒤집는다. <br/>
###### **ex) "안녕 나는 딥러닝을 좋아하는 파이썬돌이야 ." => ". 파이썬돌이야 좋아하는 딥러닝을 나는 안녕"** <br/> <br/>
###### 이렇게 언어 순서를 바꿔주는 것 만으로도 Context Vector에 다른 작용을해서 좋은 결과를 추출한다고 합니다.<br/> <br/>


## Pytorch Code
```python
class EncoderRNN(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(EncoderRNN, self).__init__()
        self.hidden_size = hidden_size
        # Layers
        self.embedding = nn.Embedding(input_size, hidden_size)
        self.gru = nn.GRU(hidden_size, hidden_size)

    def forward(self, input, hidden):
        embedded = self.embedding(input).view(1, 1, -1)
        output = embedded
        output, hidden = self.gru(output, hidden)
        return output, hidden

    def initHidden(self):
        return torch.zeros(1, 1, self.hidden_size, device=device)
```  
```python
class DecoderRNN(nn.Module):
    def __init__(self, hidden_size, output_size):
      super(DecoderRNN, self).__init__()
      self.hidden_size = hidden_size
      # Layers
      self.embedding = nn.Embedding(output_size, hidden_size)
      self.gru = nn.GRU(hidden_size, hidden_size)
      self.out = nn.Linear(hidden_size, output_size)
      self.softmax = nn.LogSoftmax(dim=1)

    
    def forward(self, input, hidden):
      output = self.embedding(input, hidden)
      output = F.relu(output)
      output, hidden = self.gru(output, hidden)
      ouptput = self.softmax(self.out(output[0]))    
      return output, hidden
    
    def initHidden(self):
      return torch.zeros(1, 1, self.hidden_size, device=device)
```  
<br/>

> ##### Reference
> * ###### https://tutorials.pytorch.kr/intermediate/seq2seq_translation_tutorial.html
> * ######  http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
> * ###### 밑바닥부터 시작하는 딥러닝 2 / 사이토 고키 / 한빛 미디어 
