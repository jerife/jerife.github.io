---
layout: post
title: CNN(Convolution Nerual Network) 이해하기
subtitle: CNN 합성곱 신경망 이해하기
gh-repo: jerife/jerife.github.io
gh-badge: [star, follow]
tags: [Computer Vision]
comments: true
toc: true
toc_sticky: true
---


## CNN이란?
CNN은 Convolution Nerual Network의 약자로서 입력값(이미지 or 텍스트)과 사용자가 지정한 필터(fitter / kernel)와 컨볼루션을 통해 특징을 추출해내는 기법이며, 우리말로 "합성곱 신경망"라고도 합니다.
CNN은 주로 이미지처리 모델링에서 많이 이용되며, 이번 글에서도 이미지를 처리한다는 상황을 가정하고 글을 작성합니다.<br/>
![214ABC4455DEBDF322](https://user-images.githubusercontent.com/68190553/117629584-48973c80-b1b5-11eb-9058-aa82af4575d2.jpeg){: .mx-auto.d-block :} <br/>
  
  
위 사진은 CNN의 구조를 보여주며, 해당 사진 속 Feature Extraction 해당하는 Convolution layer(층)과 Pooling layer(층)을 구분해 설명하고자 합니다.

***
### Convolution layer
Convolution layer에서는 CNN의 핵심이자, 위에서 말한것과 같이 입력값(이미지)과 특징을 뽑아주는 필터를 Convolution하는 층입니다. 이 과정에서 이미지는 단순히 이미지자체로만 Convolution할 순 없습니다. 우리는 컴퓨터가 이미지를 이해할 수 있게 이미지를 숫자화 시킵니다. 숫자화 된 이미지는 특징을 뽑아주는 필터와 Convolution합니다.<br/>
![IMG_5780](https://user-images.githubusercontent.com/68190553/117654131-50b0a580-b1d0-11eb-8553-02af68281ee6.jpg){: .mx-auto.d-block :} <br/>
사진을 보면 좌측의 숫자화 된 입력 이미지와 임의의 필터를 Convolution을 해줍니다. 5x5이미지가 3x3크기의 필터와 Convolution을 통해 3x3크기의 결과가 나옵니다. 우리는 이 결과를 feature map이라고 부릅니다.
더 명확한 이해를 돕기위해 움짤을 가져왔습니다.<br/>
![IMG_5776](https://user-images.githubusercontent.com/68190553/117630407-1df9b380-b1b6-11eb-9e22-9dca5f313594.GIF){: .mx-auto.d-block :} <br/>
우리는 여기서 입력 이미지의 크기 / 필터의 크기 / 필터가 이동하는 범위 / Convolution을 해도 feature map의 크기가 안줄어들게 파라미터를 조절할 수 있습니다.
#### [1] 필터의 크기
* 위 움짤에선 필터의 크기가 3x3크기로 입력 이미지를 Convolution하는 것을 알 수 있습니다. 우리는 필터의 크기를 조절해 feature map의 크기를 정할 수 있습니다

#### [2] 필터가 이동하는 범위 (스트라이드)
* 위 움짤을 보면 3x3크기의 필터가 1칸씩 움직이는걸 확인할 수 있다. 이는 stride=1 라고 이해할 수 있습니다. 우리는 stride=2 로 조절해 필터가 2칸씩 움직일 수 있게 조절할 수 있다. stride가 커질 수록 당연히 feature map의 크기는 줄어들 것 입니다.

#### [3] 패딩 <br/>
![NU7y2](https://user-images.githubusercontent.com/68190553/117656075-dc2b3600-b1d2-11eb-89e7-d9fe6ecb3a42.png){: .mx-auto.d-block :} <br/>
* 패딩이란? Convolution과정에서 입력 이미지의 크기가 줄어드는 것을 방지하기 위한 기법입니다. 기존 입력 이미지에 0값을 둘러쌓음으로써 결과로 나올 feature map의 크기를 조절합니다. 우리는 padding값을 full / same / vaild 등을 통해 조절할 수 있습니다.

### Pooling layer
풀링층에서는 데이터의 크기를 줄일 수 있습니다. 이는 모델의 입력이미지의 크기를 줄이는 동시에 자연스레 파라미터수(연산)까지 줄일 수 있으며, 딥러닝에서 모델이 깊어짐에 따라 더욱 섬세한 부분을 학습시킬 수 있는 과정입니다. (비선형적특징을 더 학습할 수 있음) 대부분의 CNN에선 Convolution layer를 거친 후 pooling layer를 통해 깊게 학습시킵니다.<br/>
![IMG_5777](https://user-images.githubusercontent.com/68190553/117657120-27921400-b1d4-11eb-8b2e-ce74a64914be.JPG){: .mx-auto.d-block :} <br/>
위 사진은 4x4크기의 입력 이미지에 2x2크기의 pooling이 적용된 사진입니다. 풀링은 convolution layer의 필터와 같이 움직입니다. 하지만, 기본적으로 Pooling layer에서의 "필터는 크기"와 "필터가 움직이는 크기"의 값이 같습니다. 즉, 필터의 값이 겹쳐서 나오지 않습니다. 위 사진에서 4x4크기의 입력 이미지가 4가지 색으로 표현되어있으며, 각 2x2크기의 필터마다 다른 색칠되어있습니다. 이는 2x2크기의 필터로 pooling을 한다고 이해하시면 되겠습니다. 덧붙여 pooling의 종류에는 크게 Average-Pooling / Max-Pooling 으로 2가지가 사용되며 밑에서 설명하겠습니다.
#### [1] Average-Pooling
* 먼저 Average-Pooling입니다. Average-Pooling은 위사진에선 4x4크기의 입력 이미지에서 2x2크기마다 평균을 구해 결과를 구합니다.

#### [2] Max-Pooling
*  Max-Pooling입니다. Max-Pooling은 위사진에 4x4크기의 입력 이미지에서 2x2크기마다 가장 큰 값을 구해 결과를 구합니다.<br/><br/>

## Pytorch Code
```python
import torch
import torch.nn as nn
 
class CNN(nn.Module):
  def __init__(self, input_channel=32, filter_size=3, stride_size=1, hidden_channel=64, output_channel=2, pooling_size=2):
    super(CNN, self).__init__()
    self.convolution_layer = nn.Conv2d(input_chanel, output_channel, filter_size, stride_size, padding=1)
    self.pooling_layer = nn.MaxPool2d(pooling_size)
    self.fc = nn.Linear(hidden_channel)
  def forward(self, x):
    out = self.convolution_layer(x)
    out = self.pooling_layer(out)
    out = out.view(-1)
    out = self.fc(out)
    return out
```
<br/>

> 이미지 출처
> * http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution
